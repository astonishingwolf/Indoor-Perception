{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import functions.pc_matching\n",
    "import functions.mat_to_py\n",
    "import functions.viz\n",
    "import functions.pc_registration\n",
    "importlib.reload(functions.pc_matching)\n",
    "importlib.reload(functions.mat_to_py)\n",
    "importlib.reload(functions.viz)\n",
    "importlib.reload(functions.pc_registration)\n",
    "from functions.pc_matching import PCMatch\n",
    "from functions.mat_to_py import PCNIData\n",
    "from functions.viz import pc_viz, video_cv, pc2video\n",
    "from functions.pc_registration import PointReg\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  C:\\Users\\dasgu\\Documents\\GithubPercep\\sensordata\\Sept_Recording\\Sep28-2022_CAM-LCR_LIDAR_applanix\\14-50-47\\imgdata\\2022-06-16-13-01-40_2_img.mat\n"
     ]
    }
   ],
   "source": [
    "datapoints = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GithubPercep\\\\sensordata\\\\Sept_Recording\\\\Sep28-2022_CAM-LCR_LIDAR_applanix\\\\14-50-47',eg=2)\n",
    "images = datapoints('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change of Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dasgu\\Documents\\GithubPercep\\IndoorPerception\\imagepipeline.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/GithubPercep/IndoorPerception/imagepipeline.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# img = images[150]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/GithubPercep/IndoorPerception/imagepipeline.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mimage_1_1000.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/GithubPercep/IndoorPerception/imagepipeline.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cv\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mPC\u001b[39;49m\u001b[39m'\u001b[39;49m,  img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/GithubPercep/IndoorPerception/imagepipeline.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cv\u001b[39m.\u001b[39mwaitKey(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/GithubPercep/IndoorPerception/imagepipeline.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m img_pred(images,\u001b[39m150\u001b[39m,\u001b[39m160\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import functions.imageprediction\n",
    "importlib.reload(functions.imageprediction)\n",
    "from functions.imageprediction import imagepred\n",
    "img_pred = imagepred() \n",
    "# img = images[150]\n",
    "# img = cv.imread('image_1_1000.png')\n",
    "# cv.imshow('PC',  img)\n",
    "# cv.waitKey(-1)\n",
    "img_pred(images,150,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv.imread(img[200])\n",
    "cv.imshow('PC',  img)\n",
    "cv.waitKey(-1)\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network.\n",
    "net = cv.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Scalar value for argument 'color' is not numeric\n>  - Scalar value for argument 'color' is not numeric\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dasgu\\Documents\\Github\\IndoorPerception\\imagepipeline.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/Github/IndoorPerception/imagepipeline.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m imag\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dasgu/Documents/Github/IndoorPerception/imagepipeline.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv\u001b[39m.\u001b[39;49mrectangle(imag, (\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m), (\u001b[39m100\u001b[39;49m,\u001b[39m100\u001b[39;49m),\u001b[39m'\u001b[39;49m\u001b[39mblue\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Scalar value for argument 'color' is not numeric\n>  - Scalar value for argument 'color' is not numeric\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
     ]
    }
   ],
   "source": [
    "imag=img.copy()\n",
    "cv.rectangle(imag, (10,10), (100,100),'blue', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('image_1_1000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_output_layers(net):   \n",
    "    layer_names = net.getLayerNames()   \n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv.putText(img, label, (x-10,y-10), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "\n",
    "    \n",
    "Width = img.shape[1]\n",
    "Height = img.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open('yolov3.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "net = cv.dnn.readNetFromDarknet('yolov4-obj.cfg', 'yolov4-obj_final.weights')\n",
    "blob = cv.dnn.blobFromImage(img, scale, (416,416), (0,0,0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(get_output_layers(net))\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[126.0, 185.0, 132, 80]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.7:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])\n",
    "indices = cv.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "print(len(indices))\n",
    "img = np.ascontiguousarray(img, dtype=np.uint8)\n",
    "for i in indices:\n",
    "    # prin\n",
    "    box = boxes[i]\n",
    "    print(box)\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    draw_prediction(img, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "\n",
    "cv.imshow(\"object detection\", img)\n",
    "cv.waitKey()  \n",
    "cv.imwrite(\"object-detection.jpg\", img)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('percep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Jan 10 2022, 15:40:15) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f52ef770f83c874c23b0fea02cb1cfd9f7179f7089ec1916e46ea761666e8eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
