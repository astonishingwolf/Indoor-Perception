{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import importlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import h5py\n",
    "import functions.pc_matching\n",
    "import functions.mat_to_py\n",
    "import functions.viz\n",
    "import functions.pc_registration\n",
    "importlib.reload(functions.pc_matching)\n",
    "importlib.reload(functions.mat_to_py)\n",
    "importlib.reload(functions.viz)\n",
    "importlib.reload(functions.pc_registration)\n",
    "from functions.pc_matching import PCMatch\n",
    "from functions.mat_to_py import PCNIData\n",
    "from functions.viz import pc_viz, video_cv, pc2video\n",
    "from functions.pc_registration import PointReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising all the DataPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_points = PCMatch()\n",
    "data_points1 = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=6)\n",
    "data_points2 = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=7)\n",
    "data_points3 = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=8)\n",
    "data_points4 = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=9)\n",
    "datapoints = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_6_pc.mat\n",
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_7_pc.mat\n",
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_8_pc.mat\n",
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_9_pc.mat\n",
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_3_pc.mat\n"
     ]
    }
   ],
   "source": [
    "data_list1 = data_points1('pc')\n",
    "data_list2 = data_points2('pc')\n",
    "data_list3 = data_points3('pc')\n",
    "data_list4 = data_points4('pc')\n",
    "data_lists = datapoints('pc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the Static Reference Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  C:\\Users\\dasgu\\Documents\\GitHubPercep\\sensordata\\Jul22data\\pcdata\\2022-06-16-13-01-40_1_pc.mat\n"
     ]
    }
   ],
   "source": [
    "static_point = PCNIData('C:\\\\Users\\\\dasgu\\\\Documents\\\\GitHubPercep\\\\sensordata\\\\Jul22data',eg=1)\n",
    "static_pc = static_point('pc')\n",
    "pc_viz(static_pc[150])\n",
    "np.save('ref/reference_pc_new.npy',static_pc[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering and Tracking of Differenet Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] Precompute neighbors.\n",
      "[Open3D DEBUG] Done Precompute neighbors.\n",
      "[Open3D DEBUG] Compute Clusters\n",
      "[Open3D DEBUG] Done Compute Clusters: 4\n",
      "point cloud has 4 clusters\n",
      "the length of the cluster and the objects are \n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import functions.ClusterFinders\n",
    "importlib.reload(functions.ClusterFinders)\n",
    "from functions.ClusterFinders import ClusterFinder\n",
    "# static_pc = np.load('reference_pc_new.npy')\n",
    "static_pc = np.load('ref/reference_pc_new.npy')\n",
    "Find = ClusterFinder()\n",
    "object,cluster = Find(static_pc,data_list3,24,26,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registration of Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of points in cluster:  52\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 52\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "0  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.446594e-02, and correspondence_set size of 52\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99394927  0.07516975 -0.08008966  0.22541532]\n",
      " [-0.080279    0.99480442 -0.06260554  0.20541082]\n",
      " [ 0.07496751  0.06865625  0.99481968 -0.01052782]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "52  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.008713e-02, and correspondence_set size of 40\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99991017  0.01328605  0.00176892  0.00675605]\n",
      " [-0.01329789  0.99988807  0.00685705  0.01117546]\n",
      " [-0.00167762 -0.00687995  0.99997493  0.0054867 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "40  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=9.701204e-03, and correspondence_set size of 54\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.998653    0.05080662 -0.01052935  0.05246637]\n",
      " [-0.05172017  0.99096661 -0.12373441  0.33004516]\n",
      " [ 0.0041477   0.12411232  0.99225951  0.07422527]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "54  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.232610e-02, and correspondence_set size of 51\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99992329 -0.00773986 -0.00966967  0.02121275]\n",
      " [ 0.00745295  0.99954103 -0.0293628   0.07211563]\n",
      " [ 0.00989249  0.02928848  0.99952205  0.01115186]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "50  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.176167e-03, and correspondence_set size of 36\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99996736 -0.00755698 -0.00285982  0.00682943]\n",
      " [ 0.00751035  0.9998441  -0.01598002  0.04041019]\n",
      " [ 0.00298014  0.01595802  0.99986822  0.00934908]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "36  points added\n",
      "Total points in aggregated point cloud  284\n"
     ]
    }
   ],
   "source": [
    "import functions.pc_registration\n",
    "importlib.reload(functions.pc_registration)\n",
    "from functions.pc_registration import PointReg\n",
    "reg_points = Find.registration(cluster,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of points in cluster:  159\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 159\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "0  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=8.153846e-01, inlier_rmse=7.203564e-02, and correspondence_set size of 159\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.98988407  0.13901918 -0.02834055  0.51153116]\n",
      " [-0.13254688  0.9773867   0.16476213 -0.01602939]\n",
      " [ 0.05060478 -0.15933896  0.98592609 -0.16620102]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "159  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=8.916667e-01, inlier_rmse=6.046268e-02, and correspondence_set size of 214\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99895114 -0.00919191 -0.04485679  0.8615367 ]\n",
      " [ 0.00705423  0.99884236 -0.04758336 -0.17385164]\n",
      " [ 0.04524224  0.04721702  0.99785956 -0.11617179]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "214  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=9.501916e-01, inlier_rmse=5.811983e-02, and correspondence_set size of 248\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99314311 -0.04291219 -0.10874419  1.34026139]\n",
      " [ 0.04925583  0.99719612  0.05633607 -0.56804835]\n",
      " [ 0.10602178 -0.06130607  0.99247214 -0.21008365]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "248  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=9.898649e-01, inlier_rmse=3.862730e-02, and correspondence_set size of 293\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99081637 -0.13108107 -0.03317649  1.53133424]\n",
      " [ 0.13229809  0.99049614  0.03761137 -0.75650977]\n",
      " [ 0.02793105 -0.04165514  0.99874156 -0.06139542]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "293  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.516056e-02, and correspondence_set size of 357\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.9953371  -0.0721363  -0.06403447  1.86501463]\n",
      " [ 0.07332619  0.99717271  0.01642759 -0.69857497]\n",
      " [ 0.0626684  -0.02104639  0.99781247 -0.10359518]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "357  points added\n",
      "Apply Generalised ICP\n",
      "RegistrationResult with fitness=9.973333e-01, inlier_rmse=2.633792e-02, and correspondence_set size of 374\n",
      "Access transformation to get result.\n",
      "Transformation after ICP is:\n",
      "[[ 0.99603704 -0.06783344 -0.05752248  2.11046548]\n",
      " [ 0.07021527  0.9967115   0.04044759 -0.80910466]\n",
      " [ 0.05458962 -0.04432626  0.99752451 -0.07019292]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "374  points added\n",
      "Total points in aggregated point cloud  1804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.81278133, -0.70387304,  2.36399841],\n",
       "       [ 3.64729309, -0.23136237,  1.77690804],\n",
       "       [ 3.64106178, -0.25650048,  1.77481008],\n",
       "       ...,\n",
       "       [ 2.83879023, -0.33993886,  2.22968288],\n",
       "       [ 2.83481644, -0.3309662 ,  2.22908991],\n",
       "       [ 2.8307489 , -0.32203591,  2.22849325]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Find.registration(cluster,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_inlier_outlier(cloud, ind):\n",
    "    inlier_cloud = cloud.select_by_index(ind)\n",
    "    outlier_cloud = cloud.select_by_index(ind, invert=True)\n",
    "\n",
    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
    "    outlier_cloud.paint_uniform_color([0, 1, 0])\n",
    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
    "    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],\n",
    "                                      zoom=0.3412,\n",
    "                                      front=[0.4257, -0.2125, -0.8795],\n",
    "                                      lookat=[2.6172, 2.0475, 1.532],\n",
    "                                      up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('percep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Jan 10 2022, 15:40:15) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f52ef770f83c874c23b0fea02cb1cfd9f7179f7089ec1916e46ea761666e8eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
